{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Klasifikace a logistická regrese\n",
    "\n",
    "  * Import používaných knihoven.\n",
    "  * Logistická regrese je v `sklearn.linear_model` jako `LogisticRegression`.\n",
    "  * Používá se pak klasicky dle obvyklého API modelů ve `scikit-learn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn import neighbors \n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Umělá data\n",
    "\n",
    "  * Vygenerujeme si umělá data s dvěma příznaky $X_0$ a $X_1$ a binární vysvětlovanou promennou.\n",
    "  * Je to směs dvou dvourozměrných Gaussiánů.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean1 = [-20, 20]\n",
    "cov1 = [[3000, 850], [850, 1000]]\n",
    "mean2 = [10, -10]\n",
    "cov2 = [[3000, 850], [850, 1000]]\n",
    "n1 = 70\n",
    "n2 = 70\n",
    "cmap_bold = ListedColormap(['#FF0000', '#00FF00'])\n",
    "\n",
    "X1 = np.random.multivariate_normal(mean1, cov1, n1)\n",
    "y1 = np.zeros(n1,dtype=\"int\")\n",
    "X2 = np.random.multivariate_normal(mean2, cov2, n2)\n",
    "y2 = np.ones(n2,dtype=\"int\")\n",
    "\n",
    "X = np.concatenate((X1,X2), axis=0)\n",
    "y = np.concatenate((y1,y2), axis=0)\n",
    "\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=cmap_bold)\n",
    "plt.xlabel('$X_0$')\n",
    "plt.ylabel('$X_1$')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# print(X)\n",
    "# print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rozhodovací hranice (boundary decision)\n",
    "\n",
    "### KNN\n",
    "\n",
    "  * Použijeme pro srovnání KNN, které známe, a ukážeme si, jak vypadá hranice, kde se mění rozhodnutí."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 0.2  # step size in the mesh\n",
    "n_neighbors = 5\n",
    "\n",
    "# Create color maps\n",
    "cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA'])\n",
    "\n",
    "for weights in ['uniform', 'distance']:\n",
    "    # we create an instance of Neighbours Classifier and fit the data.\n",
    "    clf = neighbors.KNeighborsClassifier(n_neighbors, weights=weights)\n",
    "    clf.fit(X, y)\n",
    "\n",
    "    # Plot the decision boundary. For that, we will assign a color to each\n",
    "    # point in the mesh [x_min, m_max]x[y_min, y_max].\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "    # Put the result into a color plot\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.pcolormesh(xx, yy, Z, cmap=cmap_light)\n",
    "\n",
    "    # Plot also the training points\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=cmap_bold)\n",
    "    plt.xlim(xx.min(), xx.max())\n",
    "    plt.ylim(yy.min(), yy.max())\n",
    "    plt.xlabel('$X_0$')\n",
    "    plt.ylabel('$X_1$')\n",
    "    plt.title(\"2-Class classification (k = %i, weights = '%s')\"\n",
    "              % (n_neighbors, weights))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistická regrese \n",
    "\n",
    "  * U logistické regrese je hranice dána příslušnou nadrovinou.\n",
    "  * Mohlo by se stát, že bychom vytvořili kruhovou rozhodovací hranici?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(X,y)\n",
    "print(clf.coef_, clf.intercept_)\n",
    "\n",
    "def fun(x, intercept, coef1, coef2):\n",
    "    y = (-1/coef2)*(intercept + coef1*x)\n",
    "    return y\n",
    "# uděláme vektorovou funkci aby šlapala na ndarray\n",
    "vfun = np.vectorize(fun)\n",
    "xgrid = np.linspace(-200, 200, 200)\n",
    "\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=cmap_bold)\n",
    "plt.plot(xgrid, vfun(xgrid, clf.intercept_, clf.coef_[0,0], clf.coef_[0,1]), 'k-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parciální derivace a gradient\n",
    "\n",
    "**Úkol**: Najděte gradient funkce $\\ell(\\mathbf{w})$ (viz přednášku):\n",
    "$$\n",
    "    \\ell(\\mathbf{w}) = \\sum_{i = 1}^N \\left(Y_i \\ln \\left( \\frac{e^{\\vec{w}^T \\vec{x}}}{1 + e^{\\vec{w}^T \\vec{x}}} \\right) + (1 - Y_i) \\ln \\left( \\frac{1}{1 + e^{\\vec{w}^T \\vec{x}}} \\right)\\right).\n",
    "$$\n",
    "  * Pokuste se přepsat výsledek do maticového tvaru.\n",
    "  * Projděte si [ukázku](https://courses.fit.cvut.cz/MI-MPI/media/tutorials/mpi-ukazka-1-parcialni-derivace-v1.pdf) z předmětu MI-MPI a pokuste se pochopit geometrickou interpretaci  parciální derivace a gradientu (příp. i Hessovy matice).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
